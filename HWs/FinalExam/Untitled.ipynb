{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Lince Rumainum\n",
    "#ISE-5123\n",
    "#Project: covid-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'us_states_covid19_daily.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-5751b12b0774>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0musecols\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m17\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m                     \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m                     names=colnames)\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;31m#fill na with 0s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    653\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    654\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 655\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m    964\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 966\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    967\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1580\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'allow_leading_cols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1582\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1584\u001b[0m         \u001b[1;31m# XXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__ (pandas\\_libs\\parsers.c:4209)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source (pandas\\_libs\\parsers.c:8873)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: File b'us_states_covid19_daily.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#colnames = [\"date\", \"state\",\"positive\",\"negative\",\"pending\",\"hospitalizedCurrently\",\n",
    "#           \"hospitalizedCumulative\",\"inIcuCurrently\",\"onVentilatorCurrently\",\"death\"]\n",
    "#usecols=[0,1,2,3,4,5,6,7,9,14]\n",
    "colnames = [\"date\", \"state\",\"positive\",\"negative\",\"pending\",\"hospitalizedCurrently\",\n",
    "            \"hospitalizedCumulative\",\"inIcuCurrently\",\"death\", \n",
    "            \"totalTestResults\",\"posNeg\", \"onVentilatorCurrently\"]\n",
    "dfAll = pd.read_csv('us_states_covid19_daily.csv',\n",
    "                    usecols=[0,1,2,3,4,5,6,7,14,17,18, 9],\n",
    "                    header=1,\n",
    "                    names=colnames)\n",
    "\n",
    "#fill na with 0s\n",
    "dfAll['positive'].fillna(0, inplace=True)\n",
    "dfAll['negative'].fillna(0, inplace=True)\n",
    "dfAll['pending'].fillna(0, inplace=True)\n",
    "dfAll['hospitalizedCurrently'].fillna(0, inplace=True)\n",
    "dfAll['hospitalizedCumulative'].fillna(0, inplace=True)\n",
    "dfAll['inIcuCurrently'].fillna(0, inplace=True)\n",
    "dfAll['death'].fillna(0, inplace=True)\n",
    "dfAll['totalTestResults'].fillna(0, inplace=True)\n",
    "dfAll['posNeg'].fillna(0, inplace=True)\n",
    "dfAll['onVentilatorCurrently'].fillna(0, inplace=True)\n",
    "\n",
    "#groupby Date\n",
    "n_pos_by_date = dfAll.groupby(\"date\")[\"positive\"].sum()\n",
    "n_neg_by_date = dfAll.groupby(\"date\")[\"negative\"].sum()\n",
    "n_pen_by_date = dfAll.groupby(\"date\")[\"pending\"].sum()\n",
    "n_hospCurr_by_date = dfAll.groupby(\"date\")[\"hospitalizedCurrently\"].sum()\n",
    "n_hospCumu_by_date = dfAll.groupby(\"date\")[\"hospitalizedCumulative\"].sum()\n",
    "n_icu_by_date = dfAll.groupby(\"date\")[\"inIcuCurrently\"].sum()\n",
    "n_death_by_date = dfAll.groupby(\"date\")[\"death\"].sum()\n",
    "n_totalTest_by_date = dfAll.groupby(\"date\")[\"totalTestResults\"].sum()\n",
    "n_posneg_by_date = dfAll.groupby(\"date\")[\"posNeg\"].sum()\n",
    "n_onVen_by_date = dfAll.groupby(\"date\")[\"onVentilatorCurrently\"].sum()\n",
    "\n",
    "#groupby State\n",
    "n_pos_by_state = dfAll.groupby(\"state\")[\"positive\"].sum()\n",
    "n_neg_by_state = dfAll.groupby(\"state\")[\"negative\"].sum()\n",
    "n_pen_by_date = dfAll.groupby(\"date\")[\"pending\"].sum()\n",
    "n_hospCurr_by_state = dfAll.groupby(\"state\")[\"hospitalizedCurrently\"].sum()\n",
    "n_hospCumu_by_state = dfAll.groupby(\"state\")[\"hospitalizedCumulative\"].sum()\n",
    "n_icu_by_state = dfAll.groupby(\"state\")[\"inIcuCurrently\"].sum()\n",
    "n_death_by_state = dfAll.groupby(\"state\")[\"death\"].sum()\n",
    "n_totalTest_by_state = dfAll.groupby(\"state\")[\"totalTestResults\"].sum()\n",
    "n_posneg_by_state = dfAll.groupby(\"state\")[\"posNeg\"].sum()\n",
    "n_onVen_by_state = dfAll.groupby(\"state\")[\"onVentilatorCurrently\"].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#copy to new data frame\n",
    "dfAll2 = dfAll.copy()\n",
    "#change int to strings\n",
    "dfAll2['date'] = dfAll2['date'].apply(str)\n",
    "\n",
    "#create month and day columns\n",
    "dfAll2['month'] = \"\"\n",
    "dfAll2['day'] = \"\"\n",
    "\n",
    "for i in range(0, dfAll2.shape[0]):\n",
    "    currDate = dfAll2.date[i]\n",
    "    dayStr =[]\n",
    "    for j in range(0, 3):\n",
    "        if j == 0:\n",
    "            monthInt = int(currDate[j])\n",
    "            dfAll2.month[i] = monthInt\n",
    "        else:\n",
    "            dayStr.append(currDate[j])\n",
    "    dayStr2 = dayStr[0]+dayStr[1]\n",
    "    dayInt = int(dayStr2)\n",
    "    dfAll2.day[i] = dayInt\n",
    "dfAll2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import datetime\n",
    "from datetime import date\n",
    "\n",
    "#create test date\n",
    "dfAll2['testDate'] = \"\"\n",
    "for i in range(0, dfAll2.shape[0]):\n",
    "    dfAll2.testDate[i] = date(2020, dfAll2.month[i], dfAll2.day[i])\n",
    "dfAll2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot data by date\n",
    "#get column names\n",
    "dfColNames = dfAll2.columns.tolist()\n",
    "#plot each column var with date\n",
    "for i in range(2,dfAll2.shape[1]-3):    \n",
    "    ylbl = str(dfColNames[i])\n",
    "    dfAll2.plot(x = 'testDate', y = ylbl)    \n",
    "    plt.gcf().autofmt_xdate() #x-labels: date\n",
    "    plt.ylabel(ylbl) #y-label\n",
    "    filename = ylbl + '.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#since there are barely any data before 4 March 2020\n",
    "#update data\n",
    "dfStartMarch = dfAll2[(dfAll2['testDate'] > date(2020,3,4))]\n",
    "dfStartMarch\n",
    "print(\"number of rows before:\", dfAll2.shape[0]) #check size\n",
    "print(\"number of rows after :\", dfStartMarch.shape[0]) #check size\n",
    "print(\"Percentage from original data: \" + \n",
    "      str(round(dfStartMarch.shape[0]/dfAll2.shape[0]*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#plot data that start from March\n",
    "dfColNames = dfStartMarch.columns.tolist()\n",
    "#plot each column var with date - updated data\n",
    "for i in range(2,dfStartMarch.shape[1]-3):    \n",
    "    ylbl = str(dfColNames[i])\n",
    "    dfStartMarch.plot(x = 'testDate', y = ylbl)    \n",
    "    plt.gcf().autofmt_xdate() #x-labels: date\n",
    "    plt.ylabel(ylbl) #y-label\n",
    "    filename = ylbl + 'StartMarch.png'\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "states = dfAll.state\n",
    "states = np.unique(states)\n",
    "totalPos = sum(n_pos_by_state)\n",
    "\n",
    "fractions = []\n",
    "for i  in range(0,len(states)):\n",
    "    fractions.append(n_pos_by_state[i]/totalPos)\n",
    "\n",
    "offsets = [0] * len(states)\n",
    "\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.pie(fractions, explode = offsets, labels=states, autopct='%1.1f%%', \n",
    "        startangle = 0, colors = sns.color_palette('bright'), \n",
    "        textprops={'fontsize': 25}, \n",
    "        pctdistance=1.1, labeldistance=0.75)\n",
    "plt.axis('equal')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "#plt.rcParams['lines.linewidth'] = 2\n",
    "#plt.rcParams.update({'font.size': 50})\n",
    "filename = 'allStatesPositiveCases.png'\n",
    "plt.savefig(filename)\n",
    "plt.show()\n",
    "\n",
    "#plot looks awful, continue to update with top 10 states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = dfAll.state\n",
    "states = np.unique(states)\n",
    "statesPosData = {'state': states, 'positiveCount':n_pos_by_state}\n",
    "dfPosStates = pd.DataFrame(data = statesPosData)\n",
    "dfPosStates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortPos = dfPosStates.sort_values('positiveCount', ascending=False).drop_duplicates(['state'])\n",
    "top10Pos = sortPos[:10]\n",
    "top10Pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "top10states = list(top10Pos.state)\n",
    "\n",
    "totalPos = sum(n_pos_by_state)\n",
    "\n",
    "fractions = []\n",
    "for i  in range(0,len(top10states)):\n",
    "    fractions.append(top10Pos.positiveCount[i]/totalPos)\n",
    "fractions.append(1-sum(fractions))\n",
    "\n",
    "offsets = [0.1] * len(top10states)\n",
    "offsets.append(0.5)\n",
    "\n",
    "top10states.append('Others')\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.pie(fractions, explode = offsets, labels=top10states, autopct='%1.1f%%', \n",
    "        startangle = 0, colors = sns.color_palette('bright'), \n",
    "        textprops={'fontsize': 25}, \n",
    "        pctdistance=1.1, labeldistance=0.75)\n",
    "plt.axis('equal')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "filename = 'top10StatesPositiveCases.png'\n",
    "plt.savefig(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "states = dfAll.state\n",
    "states = np.unique(states)\n",
    "statesPosData = {'state': states, 'ventilatorCount':n_onVen_by_state}\n",
    "dfPosStates = pd.DataFrame(data = statesPosData)\n",
    "dfPosStates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sortVen = dfPosStates.sort_values('ventilatorCount', ascending=False).drop_duplicates(['state'])\n",
    "top15Ven = sortVen[:15]\n",
    "top15Ven"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "top15states = list(top15Ven.state)\n",
    "\n",
    "totalVen = sum(n_onVen_by_state)\n",
    "\n",
    "fractions = []\n",
    "for i  in range(0,len(top15states)):\n",
    "    fractions.append(top15Ven.ventilatorCount[i]/totalVen)\n",
    "fractions.append(1-sum(fractions))\n",
    "\n",
    "offsets = [0.1] * len(top15states)\n",
    "offsets.append(0.25)\n",
    "\n",
    "top15states.append('Others')\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "plt.pie(fractions, explode = offsets, labels=top15states, autopct='%1.1f%%', \n",
    "        startangle = 0, colors = sns.color_palette('bright'), \n",
    "        textprops={'fontsize': 25}, \n",
    "        pctdistance=1.1, labeldistance=0.80)\n",
    "plt.axis('equal')\n",
    "plt.rcParams['text.color'] = 'black'\n",
    "filename = 'top10VentilatorNumbers.png'\n",
    "plt.savefig(filename)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get data without date and states\n",
    "dfNums = dfStartMarch[[\"positive\",\"negative\",\"pending\",\"hospitalizedCurrently\",\n",
    "            \"hospitalizedCumulative\",\"inIcuCurrently\",\"death\", \n",
    "            \"totalTestResults\",\"posNeg\", \"onVentilatorCurrently\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "y = dfNums.onVentilatorCurrently #target\n",
    "x=dfNums.drop('onVentilatorCurrently',axis=1)\n",
    "#X_scaled = preprocessing.scale(x)\n",
    "# normalize data\n",
    "#X_scaled = pd.DataFrame(preprocessing.scale(dfNums),columns = dfNums.columns) \n",
    "X_scaled = pd.DataFrame(preprocessing.scale(x),columns = dfNums.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cummulativeSum = np.cumsum(pca.explained_variance_ratio_)\n",
    "d = np.argmax(cummulativeSum >= 0.95) + 1\n",
    "\n",
    "print(\"PCA explained var ratio: \")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"cummulative sum: \")\n",
    "print(cummulativeSum)\n",
    "print(\"dimension needed to reach 95%: \",d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dump components relations with features:\n",
    "print (pd.DataFrame(pca.components_,columns=X_scaled.columns,\n",
    "                   index = ['PC-1','PC-2','PC-3','PC-4','PC-5',\n",
    "                            'PC-6','PC-7','PC-8','PC-9','PC-10','PC-11']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the PCA components (loadings)\n",
    "PCs = pca.components_\n",
    "\n",
    "# Use quiver to generate the basic plot\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "           PCs[0,:], PCs[1,:], \n",
    "           angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# Add labels based on feature names (here just numbers)\n",
    "feature_names = np.arange(PCs.shape[1])\n",
    "for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "    plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# Add unit circle\n",
    "circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "# Ensure correct aspect ratio and axis limits\n",
    "plt.axis('equal')\n",
    "plt.xlim([-1.0,1.0])\n",
    "plt.ylim([-1.0,1.0])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('PC 0')\n",
    "plt.ylabel('PC 1')\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get the PCA components (loadings)\n",
    "PCs = pca.components_\n",
    "\n",
    "# Use quiver to generate the basic plot\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "plt.quiver(np.zeros(PCs.shape[1]), np.zeros(PCs.shape[1]),\n",
    "           PCs[0,:], PCs[1,:], \n",
    "           angles='xy', scale_units='xy', scale=1)\n",
    "\n",
    "# Add labels based on feature names (here just numbers)\n",
    "feature_names = np.arange(PCs.shape[1])\n",
    "for i,j,z in zip(PCs[1,:]+0.02, PCs[0,:]+0.02, feature_names):\n",
    "    plt.text(j, i, z, ha='center', va='center')\n",
    "\n",
    "# Add unit circle\n",
    "circle = plt.Circle((0,0), 1, facecolor='none', edgecolor='b')\n",
    "plt.gca().add_artist(circle)\n",
    "\n",
    "# Ensure correct aspect ratio and axis limits\n",
    "plt.axis('equal')\n",
    "plt.xlim([-0.5,1.0])\n",
    "plt.ylim([-0.1,0.1])\n",
    "\n",
    "# Label axes\n",
    "plt.xlabel('PC 0')\n",
    "plt.ylabel('PC 1')\n",
    "\n",
    "# Done\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Linear model\n",
    "import sklearn.linear_model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2)\n",
    "print (X_train.shape, y_train.shape)\n",
    "print (X_test.shape, y_test.shape)\n",
    "\n",
    "lm = sklearn.linear_model.LinearRegression()\n",
    "model = lm.fit(X_train, y_train)\n",
    "predictions = lm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.scatter(y_test, predictions)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Score:\", model.score(X_test, y_test))\n",
    "#linear model is bad model for this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#non-linear regression --> random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "rf = sklearn.ensemble.RandomForestClassifier(n_estimators = 200, max_depth=1000, \n",
    "                                             random_state=0, n_jobs = 4)\n",
    "model2 = rf.fit(X_train, y_train)\n",
    "predictions2 = rf.predict(X_test)\n",
    "plt.scatter(y_test, predictions2)\n",
    "plt.xlabel(\"True Values\")\n",
    "plt.ylabel(\"Predictions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Score:\", model2.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print level of importance\n",
    "dfColNames = dfNums.columns.tolist()\n",
    "for i in range(len(dfColNames)-1):\n",
    "    print(dfColNames[i] + \": \" + \n",
    "          str(round(rf.feature_importances_[i]*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#random forest\n",
    "clf = RandomForestClassifier(n_estimators = 9, max_depth=45, random_state=0)\n",
    "clfModel = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dfColNames = dfNums.columns.tolist()\n",
    "for i in range(len(dfColNames)):\n",
    "    print(dfColNames[i] + \": \" + \n",
    "          str(round(rf.feature_importances_[i]*100,2)) + \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"Score:\", clfModel.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
